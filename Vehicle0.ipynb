{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ynGqnMq3YXxQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('in-vehicle-coupon-recommendation.csv')"
      ],
      "metadata": {
        "id": "jimEHTuLYs47"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values = df.isna().sum()"
      ],
      "metadata": {
        "id": "rm8qFBfWY6Dl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Missing values per column:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFTZKn4DZPRB",
        "outputId": "1089ad48-d0da-4741-902d-c985916e387c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values per column:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(missing_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGtGTEoyZUmR",
        "outputId": "5584cb03-62f0-4822-d9be-1ee0e78d52d7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "destination                 0\n",
            "passanger                   0\n",
            "weather                     0\n",
            "temperature                 0\n",
            "time                        0\n",
            "coupon                      0\n",
            "expiration                  0\n",
            "gender                      0\n",
            "age                         0\n",
            "maritalStatus               0\n",
            "has_children                0\n",
            "education                   0\n",
            "occupation                  0\n",
            "income                      0\n",
            "car                     12576\n",
            "Bar                       107\n",
            "CoffeeHouse               217\n",
            "CarryAway                 151\n",
            "RestaurantLessThan20      130\n",
            "Restaurant20To50          189\n",
            "toCoupon_GEQ5min            0\n",
            "toCoupon_GEQ15min           0\n",
            "toCoupon_GEQ25min           0\n",
            "direction_same              0\n",
            "direction_opp               0\n",
            "Y                           0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_missing = df.isna().sum().sum()\n",
        "print(f\"\\nTotal missing values in the dataset: {total_missing}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfxeFUtqZav_",
        "outputId": "afc89433-1fc5-4296-db32-c827107215ef"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total missing values in the dataset: 13370\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The df.isna().sum() function is used to find the total sum of the numbers of the missing columns."
      ],
      "metadata": {
        "id": "SYJkpIizZikH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To handle the missing values the removal technique has been used."
      ],
      "metadata": {
        "id": "M60zNgVZZ_4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "dapXESe8aIgH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "sYcDN3aqaQ8O"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first command is used to to remove rows with missing values and the second command is used to remove the missing values in the columns."
      ],
      "metadata": {
        "id": "e_GVaPu4aTOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "duplicateRows = df[df.duplicated()]\n",
        "print(f\"Duplicate rows:\\n{duplicateRows}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6iVJywzbBRq",
        "outputId": "45693a28-62c1-49c2-ade7-5a1cf8c97548"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duplicate rows:\n",
            "Empty DataFrame\n",
            "Columns: [destination, passanger, weather, temperature, time, coupon, expiration, gender, age, maritalStatus, has_children, education, occupation, income, car, Bar, CoffeeHouse, CarryAway, RestaurantLessThan20, Restaurant20To50, toCoupon_GEQ5min, toCoupon_GEQ15min, toCoupon_GEQ25min, direction_same, direction_opp, Y]\n",
            "Index: []\n",
            "\n",
            "[0 rows x 26 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above command is used to print the duplicate rows of the dataset."
      ],
      "metadata": {
        "id": "OXvVBY2wbOno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "y36hPMIhbqlh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above command removes the duplicate rows."
      ],
      "metadata": {
        "id": "9LP9MV1Qbsyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Shape after removing duplicates: {df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDofDEXdb1oh",
        "outputId": "4b33f751-2eb9-4f22-c6d3-9fec53129f38"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape after removing duplicates: (108, 26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above command shows the shape of the dataset after removing duplicate elements .i.e, the no. of rows and the no. of columns left."
      ],
      "metadata": {
        "id": "C66iC3Tob4dS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('cleaned_dataset.csv', index=False)\n",
        "print(\"\\nCleaned dataset saved as 'cleaned_dataset.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TM3vhe2cM1E",
        "outputId": "f55ff31b-14d1-4e52-903e-89397092d3c1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cleaned dataset saved as 'cleaned_dataset.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('cleaned_dataset.csv')"
      ],
      "metadata": {
        "id": "9pxCSbyPcfph"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7720c1DOc5R8",
        "outputId": "99473bc5-4e50-4337-8976-0fc88185300f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         destination  passanger weather  temperature  time  \\\n",
            "0    No Urgent Place      Alone   Sunny           55   2PM   \n",
            "1    No Urgent Place  Friend(s)   Sunny           80  10AM   \n",
            "2    No Urgent Place  Friend(s)   Sunny           80  10AM   \n",
            "3    No Urgent Place  Friend(s)   Sunny           80  10AM   \n",
            "4    No Urgent Place  Friend(s)   Sunny           80   2PM   \n",
            "..               ...        ...     ...          ...   ...   \n",
            "103             Work      Alone   Rainy           55   7AM   \n",
            "104             Work      Alone   Rainy           55   7AM   \n",
            "105             Work      Alone   Snowy           30   7AM   \n",
            "106             Work      Alone   Snowy           30   7AM   \n",
            "107             Work      Alone   Sunny           80   7AM   \n",
            "\n",
            "                    coupon expiration gender  age maritalStatus  ...  \\\n",
            "0          Restaurant(<20)         1d   Male   26        Single  ...   \n",
            "1             Coffee House         2h   Male   26        Single  ...   \n",
            "2                      Bar         1d   Male   26        Single  ...   \n",
            "3    Carry out & Take away         2h   Male   26        Single  ...   \n",
            "4             Coffee House         1d   Male   26        Single  ...   \n",
            "..                     ...        ...    ...  ...           ...  ...   \n",
            "103        Restaurant(<20)         2h   Male   21        Single  ...   \n",
            "104      Restaurant(20-50)         1d   Male   21        Single  ...   \n",
            "105        Restaurant(<20)         2h   Male   21        Single  ...   \n",
            "106      Restaurant(20-50)         1d   Male   21        Single  ...   \n",
            "107        Restaurant(<20)         1d   Male   21        Single  ...   \n",
            "\n",
            "     CoffeeHouse CarryAway RestaurantLessThan20 Restaurant20To50  \\\n",
            "0            4~8       4~8                  1~3            never   \n",
            "1            4~8       4~8                  1~3            never   \n",
            "2            4~8       4~8                  1~3            never   \n",
            "3            4~8       4~8                  1~3            never   \n",
            "4            4~8       4~8                  1~3            never   \n",
            "..           ...       ...                  ...              ...   \n",
            "103        less1       1~3                less1            less1   \n",
            "104        less1       1~3                less1            less1   \n",
            "105        less1       1~3                less1            less1   \n",
            "106        less1       1~3                less1            less1   \n",
            "107        less1       1~3                less1            less1   \n",
            "\n",
            "    toCoupon_GEQ5min toCoupon_GEQ15min toCoupon_GEQ25min direction_same  \\\n",
            "0                  1                 0                 0              0   \n",
            "1                  1                 0                 0              0   \n",
            "2                  1                 0                 0              0   \n",
            "3                  1                 1                 0              0   \n",
            "4                  1                 0                 0              0   \n",
            "..               ...               ...               ...            ...   \n",
            "103                1                 1                 1              0   \n",
            "104                1                 1                 1              0   \n",
            "105                1                 1                 1              0   \n",
            "106                1                 1                 1              0   \n",
            "107                1                 0                 0              1   \n",
            "\n",
            "    direction_opp  Y  \n",
            "0               1  1  \n",
            "1               1  0  \n",
            "2               1  1  \n",
            "3               1  0  \n",
            "4               1  1  \n",
            "..            ... ..  \n",
            "103             1  1  \n",
            "104             1  1  \n",
            "105             1  1  \n",
            "106             1  1  \n",
            "107             0  1  \n",
            "\n",
            "[108 rows x 26 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The final output is the cleaned dataset after removing all the duplicate rows and\n",
        "columns."
      ],
      "metadata": {
        "id": "Zb6amj5Odvvr"
      }
    }
  ]
}